{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a873471-6d64-4752-b74a-ff48dec668a8",
   "metadata": {},
   "source": [
    "## Q-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa14ff6-3126-41c7-9d19-962590a073f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Overfitting and underfitting in machine learning : Overfitting occur when a model learn noise in the training data instead of\n",
    "learning the underlying pattern to achieve a generalised model which in turn results low accuracy while testing the model.\n",
    "Underfitting occur when a model is too simple and or train with very few epoch result in low training and testing accuracy.\n",
    "\n",
    "Consequences : model will not generalize well to new data, leading to poor performance and inaccurate predictions.\n",
    "\n",
    "how can they be mitigated?\n",
    "L1 and L2 regularization techniques is done to avoid overfitting\n",
    "Underfitting can be avoided by increasing the complexity of the model, increase the no. of features, training model for more \n",
    "epochs.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cdbb77-653e-46c6-9dc3-668d455e5496",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f5613-715c-4bfa-80f0-bdfe6b3008b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To mitigate overfitting, one can use regularization techniques such as L1 and L2 regularization, which add a penalty term to\n",
    "the loss function to prevent the model from overfitting the training data. Another approach is to use early stopping, which\n",
    "stops the training process when the model's performance on the validation set stops improving.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c27dd-1f58-423f-8aa8-e83515d21192",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2830b8-2be5-4bb3-b9ea-5e4b90663f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Underfitting : It occur when the model is too simple and the training data is not sufficient which in-turn model cannot achieve\n",
    "enough accuracy.\n",
    "\n",
    "Some scenerio:\n",
    "1. lack of training data\n",
    "2. poor selection of features for training the model\n",
    "3. low complexity of model\n",
    "4. inappropriate regularization\n",
    "5. early stoppage of training\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33c882-9f1d-4f32-8638-706431f3d012",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07d9a5-a1d3-44b7-940b-cddbd7f6b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The bias of a model refers to the degree to which the model's predictions differ from the true values, while the variance of a\n",
    "model refers to the degree to which the model's predictions vary for different training data.\n",
    "\n",
    "Relationships between bias & variance : \n",
    "\n",
    "High bias low variance: underfitting scenerio where model is trained with sufficient data so it is unable to generalized for new data\n",
    "Low bias high variance: overfitting scenerio where model is fitted too closely with the training data which results high variance from the actual values to the predicted values.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b387c-ccef-4101-a6ec-15979b095b81",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07f098-b16e-4366-9ad1-61f037360ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Some common methods for detecting overfitting and underfitting in machine learning models:\n",
    "--Cross-validation: model performs well on the training data but poorly on the validation data, it may indicate overfitting.\n",
    "--Regularization: Regularization is a technique for preventing overfitting by adding a penalty term to the loss function that \n",
    "                encourages the model to have small weights. \n",
    "--Feature importance: If some features have low importance, it may indicate underfitting, while if some features have high importance,\n",
    "                      it may indicate overfitting.\n",
    "   \n",
    "   \n",
    "Determining whether the model is overfitting or underfitting:-\n",
    "\n",
    "To determine whether a model is overfitting or underfitting, it is important to evaluate the model's performance on both \n",
    "the training and test data. If the model has high training error and high test error, it may indicate underfitting, \n",
    "and the model may need to be made more complex or the features may need to be improved. If the model has low training error \n",
    "and high test error, it may indicate overfitting, and the model may need to be regularized or simplified.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce90fda3-b7a2-41f2-a0f2-fad6d1adc029",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df204408-0821-4e01-8cb9-0e2d2cd76e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Bias : Refers to the degree to which the model's predictions differ from the true values.\n",
    "High bias models - high bias models include linear regression with a low degree polynomial, or a decision tree with a shallow depth.\n",
    "Variance: refers to the degree to which the model's predictions vary for different training data. \n",
    "High variance models - ensemble and decision tree with large depth\n",
    "\n",
    "This means that high bias models may perform consistently across different data sets, but their predictions may be far from \n",
    "the true values. High variance models, on the other hand, may fit very closely to the training data, but may perform poorly on\n",
    "new, unseen data.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2256b8-ba70-4558-96ea-8fe0135fd37f",
   "metadata": {},
   "source": [
    "## Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965e5b8-4ba4-4471-9c7c-ab919db0dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Regularization is a technique used in machine learning to prevent overfitting and improve the generalization performance of a\n",
    "model. Overfitting occurs when a model is too complex and fits too closely to the training data, resulting in poor performance \n",
    "on new, unseen data. Regularization adds a penalty term to the loss function of the model to discourage it from fitting too\n",
    "closely to the training data.\n",
    "\n",
    "L1 regularization (Lasso regularization): L1 regularization adds a penalty term to the loss function that is proportional to \n",
    "the absolute value of the model weights. This results in sparse models where some of the weights are set to zero, effectively\n",
    "removing some of the features from the model. This can be useful for feature selection and reducing model complexity.\n",
    "\n",
    "L2 regularization (Ridge regularization): L2 regularization adds a penalty term to the loss function that is proportional to \n",
    "the square of the model weights. This results in smoother models with smaller weights, which can reduce the sensitivity of the\n",
    "model to small changes in the input data.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
